---
title: 'Homework 6: Linear Models'
author: "Jessica Lavery"
date: "Due 11/25/2019"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(kableExtra)
library(patchwork)
library(modelr)

# set seed for cross validation and bootstrapping so that results are reproducible 
set.seed(1123)

# set theme for ggplot
theme_set(theme_bw() + theme(legend.position = "bottom"))
```

# Problem 1

```{r}
# read in and tidy the data
raw_data <- read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names() 

tidy_data <- raw_data %>% 
  mutate(babysex = factor(case_when(babysex == 1 ~ "Male",
                             babysex == 2 ~ "Female"), levels = c("Male", "Female")),
         father_race = fct_reorder(as_factor(case_when(frace == 1 ~ "White",
                           frace == 2 ~ "Black",
                           frace == 3 ~ "Asian",
                           frace == 4 ~ "Puerto Rican",
                           frace == 8 ~ "Other",
                           TRUE ~ as.character(NA))),  frace),
         mother_race = fct_reorder(as_factor(case_when(frace == 1 ~ "White",
                           frace == 2 ~ "Black",
                           frace == 3 ~ "Asian",
                           frace == 4 ~ "Puerto Rican",
                           frace == 8 ~ "Other",
                           TRUE ~ as.character(NA))),  mrace))
```

Since we are going to be fitting a model we will start by looking at a summary of the data. In particular we will look at the amount of missingness and the levels of each variable. 

```{r}
skimr::skim(tidy_data)
```

Before fitting a linear model we will plot the distribution of birthweight to ensure that a linear model is appropriate. Based on the below histogram, the data are normally distributed with mean `r round(mean(pull(tidy_data, bwt)),0)` grams and a linear model is appropriate for the outcome of birthweight. 

```{r}
# plot the raw birthweight data
ggplot(data = tidy_data, aes(x = bwt)) +
  geom_histogram() +
  labs(x = "Birthweight (grams)",
       y = "Count",
       title = "Distribution of birthweight")
```


```{r, include = FALSE}
# look at levels of factor variables (output suppressed)
tidy_data %>% 
  select_if(is.factor) %>% 
  map(table, useNA = "always")
```

The following linear model is based on pre-specification of the relevant covariates a priori, meaning tht variables included were variables that are hypothesized to be related to birthweight rather than model selection via data driven approach. Binary or categorical covariates with small cell sizes were not included in the model since they would advsersely affect model fit. Examples of such variables that were considered but not included due to low cell counts or fewer than two levels were: `malform` (n=`r nrow(tidy_data %>% filter(malform == 1))`), `pnumsga` (n=`r nrow(tidy_data %>% filter(pnumsga != 0))`).

```{r}
# propose a linear model for the data
mdl_bwt <- lm(bwt ~ babysex + gaweeks + blength + bhead + smoken, data = tidy_data)

broom::tidy(mdl_bwt) %>% 
  mutate(p_value = format.pval(p.value, digits = 2, eps = 0.001)) %>% 
  select(-p.value) %>% 
  kable()
```

## Residuals vs predicted values

```{r}
tidy_data %>% 
  add_residuals(mdl_bwt) %>% 
  add_predictions(mdl_bwt) %>% 
  # filter(pred > 0) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.6) + 
  geom_hline(yintercept = 0) + 
  # geom_smooth(method = "loess", se = TRUE) + 
  labs(title = "Residuals vs predicted values for linear model of birthweight",
       caption = "Model adjusted for: baby's sex, gestational age, baby's length (cm), baby's head circumference, and number of cigarettes per day during pregnancy.",
       x = "Predicted values",
       y = "Residuals")
```

There is are three babies whose predicted birthweight is less than 0, but they are clear outliers in the data. For the majority of the data, the residuals are generally evenly dispersed across the predicted values.

## Model comparisons

```{r}
# cross-validate to get standard errors for alt_model1
# generate test-training pairs for cross-validation
cv <- crossv_mc(tidy_data, 100) %>% 
  # format the cross validated datasets as tibbles
  mutate(train = map(train, as_tibble),
    test = map(test, as_tibble)) %>% 
  # run each of the models
  mutate(primary_model  = map(train, ~lm(bwt ~ babysex + gaweeks + blength + bhead + smoken, data = .x)),
         alt_model1  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         alt_model2  = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))) %>% 
  # pull out root mses
  mutate(rmse_primary = map2_dbl(primary_model, test, ~rmse(model = .x, data = .y)),
         rmse_alt1 = map2_dbl(alt_model1, test, ~rmse(model = .x, data = .y)),
         rmse_alt2 = map2_dbl(alt_model2, test, ~rmse(model = .x, data = .y)))

# use ggplot to assess model fit
cv %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = case_when(model == "primary" ~ "Primary model",
                           model == "alt1" ~ "Alternative model 1",
                           model == "alt2" ~ "Alternative model 2"),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(title = "Birthweight model comparison",
       x = "Model",
       y = "Root mean squre error (RMSE)",
       caption = "Alternative model 1 adjusted for length at birth and gestational age; Alternative model 2 adjusted for head circumference, length, sex, and all interactions.")
```

The first alternative model (adjusted only for length at birth and gestational age) had the highest RMSE, indicating poorest predictive value. THe primary model (adjusted for baby's sex, gestational age, baby's length (cm), baby's head circumference, and number of cigarettes per day during pregnancy) and the second alternative model (adjusted for head circumference, length, sex, and all interactions) were comparable in terms of their RMSE, with the primary model having slightly lower RMSE than the second alternative model. 

# Problem 2

```{r}
# read in raw data
weather_df <- rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"),
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(name = recode(id, USW00094728 = "CentralPark_NY"),
         tmin = tmin / 10,
         tmax = tmax / 10) %>%
  select(name, id, everything())
```

## Bootstrap

```{r, message=FALSE}
# 1. select bootstrap samples
bootstrap_samples <- weather_df %>% 
  modelr::bootstrap(n = 5000)

# 2. on each bootstrapped sample, run a linear model and extract relevant information 
bootstrap_models <- bootstrap_samples %>% 
  mutate(models = map(strap, ~lm(tmax ~ tmin, data = .x)),
         results = map(models, broom::tidy),
         r2 = map(models, broom::glance)) %>% 
  select(-strap, -models) %>%
  unnest(c(results, r2), names_repair = "universal") %>% 
  select(.id, term, estimate, r.squared) %>% 
  pivot_wider(id_cols = c(.id, r.squared),
              names_from = term,
              values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = "tmin") %>% 
  mutate(logb0b1 = log(beta0 * beta1)) 

head(bootstrap_models)

# 3. plot the distribution of the estimates of interest
dist_r2 <- ggplot(data = bootstrap_models, aes(x = r.squared)) + 
  geom_histogram() +
  labs(x = "R-squared",
       y = "Count",
       title = "Distribution of R-squared")

dist_logb0b1 <- ggplot(data = bootstrap_models, aes(x = logb0b1)) + 
  geom_histogram() +
  labs(x = "Log(beta0 * beta1)",
       y = "Count",
       title = "Distribution of log(beta0 * beta1)")

dist_r2 / dist_logb0b1

#4. summarize bootstrapped reuslts
bootstrap_summary <- bootstrap_models %>% 
  summarize(r2_mean = round(mean(r.squared), 2),
         r2_lower = round(quantile(r.squared, probs = 0.025), 2),
         r2_upper = round(quantile(r.squared, probs = 0.975), 2),
         logb0b1_mean = round(mean(logb0b1), 2),
         logb0b1_lower = round(quantile(logb0b1, probs = 0.025), 2),
         logb0b1_upper = round(quantile(logb0b1, probs = 0.975), 2)) 
```

R-squared is approximately normally distributed with mean `r pull(bootstrap_summary, r2_mean)`. The 95% CI for the r-squared value is (`r pull(bootstrap_summary, r2_lower)`, `r pull(bootstrap_summary, r2_upper)`).

Log(beta0*beta1) is also normally distributed with mean `r pull(bootstrap_summary, logb0b1_mean)`. 
The 95% CI for log(b0 * b1) is (`r pull(bootstrap_summary, logb0b1_lower)`, `r pull(bootstrap_summary, logb0b1_upper)`).